{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "\n",
    "import argparse\n",
    "import scipy\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import easydict\n",
    "import pickle\n",
    "import copyreg\n",
    "import types\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchsummary import summary\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import csv\n",
    "import timeit\n",
    "from multiprocessing import Pool \n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "\n",
    "affine_par = True\n",
    "\n",
    "#Check number of GPU's available\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "input_size_list = [64, 64, 64, 256, 64, 64, 256, 64, 64, 256, 128, 128, 512, 128, 128, 512, 128, 128, 512, 128, 128, 512, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 256, 256, 1024, 512, 512, 2048, 512, 512, 2048, 512, 512, 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1,
     8,
     13,
     26,
     101,
     118,
     137,
     149,
     271,
     294,
     298
    ]
   },
   "outputs": [],
   "source": [
    "# Deeplab models/modules\n",
    "def outS(i):\n",
    "    i = int(i)\n",
    "    i = (i+1)/2\n",
    "    i = int(np.ceil((i+1)/2.0))\n",
    "    i = (i+1)/2\n",
    "    return i\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n",
    "        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "\n",
    "        padding = dilation\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n",
    "                               padding=padding, bias=False, dilation = dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n",
    "        for i in self.bn2.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n",
    "        for i in self.bn3.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual = x\n",
    "        \n",
    "        if type(x) is tuple:\n",
    "            x = x[0]\n",
    "            residual = x[0]\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out1 = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out1)\n",
    "        out = self.bn2(out)\n",
    "        out2 = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out2)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out3 = self.relu(out)\n",
    "\n",
    "        # Grabbing intermediate activations\n",
    "        activations.append(out1)\n",
    "        activations.append(out2)\n",
    "        activations.append(out3)\n",
    "        \n",
    "        return out3\n",
    "\n",
    "class Classifier_Module(nn.Module):\n",
    "\n",
    "    def __init__(self, dilation_series, padding_series, num_classes):\n",
    "        super(Classifier_Module, self).__init__()\n",
    "        self.conv2d_list = nn.ModuleList()\n",
    "        for dilation, padding in zip(dilation_series, padding_series):\n",
    "            self.conv2d_list.append(nn.Conv2d(2048, num_classes, kernel_size=3, stride=1, padding=padding, dilation=dilation, bias = True))\n",
    "\n",
    "        for m in self.conv2d_list:\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv2d_list[0](x)\n",
    "        for i in range(len(self.conv2d_list)-1):\n",
    "            out += self.conv2d_list[i+1](x)\n",
    "        return out\n",
    "\n",
    "class Residual_Covolution(nn.Module):\n",
    "    def __init__(self, icol, ocol, num_classes):\n",
    "        super(Residual_Covolution, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(icol, ocol, kernel_size=3, stride=1, padding=12, dilation=12, bias=True)\n",
    "        self.conv2 = nn.Conv2d(ocol, num_classes, kernel_size=3, stride=1, padding=12, dilation=12, bias=True)\n",
    "        self.conv3 = nn.Conv2d(num_classes, ocol, kernel_size=1, stride=1, padding=0, dilation=1, bias=True)\n",
    "        self.conv4 = nn.Conv2d(ocol, icol, kernel_size=1, stride=1, padding=0, dilation=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dow1 = self.conv1(x)\n",
    "        dow1 = self.relu(dow1)\n",
    "        seg = self.conv2(dow1)\n",
    "        inc1 = self.conv3(seg)\n",
    "        add1 = dow1 + self.relu(inc1)\n",
    "        inc2 = self.conv4(add1)\n",
    "        out = x + self.relu(inc2)\n",
    "        return out, seg\n",
    "\n",
    "class Residual_Refinement_Module(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(Residual_Refinement_Module, self).__init__()\n",
    "        self.RC1 = Residual_Covolution(2048, 512, num_classes)\n",
    "        self.RC2 = Residual_Covolution(2048, 512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, seg1 = self.RC1(x)\n",
    "        _, seg2 = self.RC2(x)\n",
    "        return [seg1, seg1+seg2]\n",
    "\n",
    "class ResNet_Refine(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet_Refine, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine = affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
    "        self.layer5 = Residual_Refinement_Module(num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        #        for i in m.parameters():\n",
    "        #            i.requires_grad = False\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion or dilation == 2 or dilation == 4:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion,affine = affine_par))\n",
    "        for i in downsample._modules['1'].parameters():\n",
    "            i.requires_grad = False\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride,dilation=dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        return x     \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine = affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
    "        self.layer5 = self._make_pred_layer(Classifier_Module, [6,12,18,24],[6,12,18,24],num_classes)\n",
    "        \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion or dilation == 2 or dilation == 4:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion,affine = affine_par))\n",
    "            \n",
    "        for i in downsample._modules['1'].parameters():\n",
    "            i.requires_grad = False\n",
    "        layers = []\n",
    "        activations = []\n",
    "        layers.append(block(self.inplanes, planes, stride,dilation=dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_pred_layer(self,block, dilation_series, padding_series,num_classes):\n",
    "        return block(dilation_series,padding_series,num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x1 = self.relu(x)\n",
    "        \n",
    "        # Grabbing intermediate activations\n",
    "        activations.append(x1)\n",
    "        \n",
    "        x = self.maxpool(x1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "class MS_Deeplab(nn.Module):\n",
    "    def __init__(self,block,num_classes):\n",
    "        super(MS_Deeplab,self).__init__()\n",
    "        self.Scale = ResNet(block,[3, 4, 23, 3],num_classes)   #changed to fix #4 \n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.Scale(x) # for original scale\n",
    "        output_size = output.size()[2]\n",
    "        input_size = x.size()[2]\n",
    "\n",
    "        self.interp1 = nn.Upsample(size=(int(input_size*0.75)+1, int(input_size*0.75)+1), mode='bilinear')\n",
    "        self.interp2 = nn.Upsample(size=(int(input_size*0.5)+1, int(input_size*0.5)+1), mode='bilinear')\n",
    "        self.interp3 = nn.Upsample(size=(output_size, output_size), mode='bilinear')\n",
    "\n",
    "        x75 = self.interp1(x)\n",
    "        output75 = self.interp3(self.Scale(x75)) # for 0.75x scale\n",
    "\n",
    "        x5 = self.interp2(x)\n",
    "        output5 = self.interp3(self.Scale(x5))\t# for 0.5x scale\n",
    "\n",
    "        out_max = torch.max(torch.max(output, output75), output5)\n",
    "        return [output, output75, output5, out_max]\n",
    "\n",
    "def Res_Ms_Deeplab(num_classes=21):\n",
    "    model = MS_Deeplab(Bottleneck, num_classes)\n",
    "    return model\n",
    "\n",
    "def Res_Deeplab(num_classes=21, is_refine=False):\n",
    "    if is_refine:\n",
    "        model = ResNet_Refine(Bottleneck,[3, 4, 23, 3], num_classes)\n",
    "    else:\n",
    "        model = ResNet(Bottleneck,[3, 4, 23, 3], num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# My modules\n",
    "class Decoder_Multiclass_Weighting(nn.Module):\n",
    "    def __init__(self, channel_size, num_classes):\n",
    "        super(Decoder_Multiclass_Weighting, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels = channel_size, out_channels=128, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(128, affine = True)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer2 = nn.Conv2d(in_channels = 128 , out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64, affine = True)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.predict = nn.Conv2d(in_channels = 64, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        torch.nn.init.kaiming_normal_(self.layer1.weight.data)\n",
    "        torch.nn.init.kaiming_normal_(self.predict.weight.data)\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.predict(output)\n",
    "        return output\n",
    "    \n",
    "class Decoder_Multiclass_Weighting_Deep(nn.Module):\n",
    "    def __init__(self, channel_size, num_classes):\n",
    "        super(Decoder_Multiclass_Weighting_Deep, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels = channel_size, out_channels=128, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(128, affine = True)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer2 = nn.Conv2d(in_channels = 128 , out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64, affine = True)\n",
    "        for i in self.bn2.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer3 = nn.Conv2d(in_channels = 64 , out_channels=64, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(64, affine = True)\n",
    "        for i in self.bn3.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer4 = nn.Conv2d(in_channels = 64 , out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn4 = nn.BatchNorm2d(32, affine = True)\n",
    "        for i in self.bn4.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer5 = nn.Conv2d(in_channels = 32 , out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn5 = nn.BatchNorm2d(32, affine = True)\n",
    "        for i in self.bn5.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.predict = nn.Conv2d(in_channels = 32, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        torch.nn.init.kaiming_normal_(self.layer1.weight.data)\n",
    "        torch.nn.init.kaiming_normal_(self.predict.weight.data)\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.layer4(output)\n",
    "        output = self.bn4(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.layer5(output)\n",
    "        output = self.bn5(output)\n",
    "        output = self.relu5(output)\n",
    "        output = self.predict(output)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class Decoder_Binary_weighting(nn.Module):\n",
    "    def __init__(self, channel_size, num_classes):\n",
    "        super(Decoder_Binary_weighting, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels = channel_size, out_channels=128, kernel_size=5, stride=1, padding=0)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(128, affine = True)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layer2 = nn.Conv2d(in_channels = 128 , out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(64, affine = True)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.predict = nn.Conv2d(in_channels = 64, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        torch.nn.init.kaiming_normal_(self.layer1.weight.data)\n",
    "        torch.nn.init.kaiming_normal_(self.predict.weight.data)\n",
    "\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.predict(output)\n",
    "        return output   \n",
    "\n",
    "class Decoder_Binary(nn.Module):\n",
    "    def __init__(self, channel_size):\n",
    "        super(Decoder_Binary, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels = channel_size, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine = True)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.predict = nn.Conv2d(in_channels = 64, out_channels=2, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.layer1.weight.data.normal_(0, 0.1)\n",
    "        self.predict.weight.data.normal_(0, 0.1)\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.predict(output)\n",
    "        return output\n",
    "\n",
    "class Decoder_Small(nn.Module):\n",
    "    def __init__(self, channel_size):\n",
    "        super(Decoder_Small, self).__init__()\n",
    "        self.predict = nn.Conv2d(in_channels = channel_size, out_channels=2, kernel_size=1, stride=1, padding=0)\n",
    "        self.predict.weight.data.normal_(0, 0.1)\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.predict(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     88
    ]
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class VOCDataSet(data.Dataset):\n",
    "    def __init__(self, root, list_path, max_iters=None, crop_size=(321, 321), mean=(128, 128, 128), scale=True, mirror=True, ignore_label=255):\n",
    "        self.root = root\n",
    "        self.list_path = list_path\n",
    "        self.crop_h, self.crop_w = crop_size\n",
    "        self.scale = scale\n",
    "        self.ignore_label = ignore_label\n",
    "        self.mean = mean\n",
    "        self.is_mirror = mirror\n",
    "        # self.mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n",
    "        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n",
    "        if not max_iters==None:\n",
    "            self.img_ids = self.img_ids * int(np.ceil(float(max_iters)/len(self.img_ids)))\n",
    "        self.files = []\n",
    "        # for split in [\"train\", \"trainval\", \"val\"]:\n",
    "        for name in self.img_ids:\n",
    "            img_file   = osp.join(self.root, \"JPEGImages/%s.jpg\" % name)\n",
    "            label_file = osp.join(self.root, \"SegmentationClassAug/%s.png\" % name)\n",
    "            self.files.append({\n",
    "                \"img\": img_file,\n",
    "                \"label\": label_file,\n",
    "                \"name\": name\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def generate_scale_label(self, image, label):\n",
    "        f_scale = 0.5 + random.randint(0, 11) / 10.0\n",
    "        image = cv2.resize(image, None, fx=f_scale, fy=f_scale, interpolation = cv2.INTER_LINEAR)\n",
    "        label = cv2.resize(label, None, fx=f_scale, fy=f_scale, interpolation = cv2.INTER_NEAREST)\n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        datafiles = self.files[index]\n",
    "        \n",
    "        image = cv2.imread( datafiles[\"img\"],   cv2.IMREAD_COLOR)\n",
    "        label = cv2.imread(datafiles[\"label\"], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        size = image.shape\n",
    "        name = datafiles[\"name\"]\n",
    "        if self.scale:\n",
    "            image, label = self.generate_scale_label(image, label)\n",
    "        image = np.asarray(image, np.float32)\n",
    "        image -= self.mean\n",
    "        img_h, img_w = label.shape\n",
    "        pad_h = max(self.crop_h - img_h, 0)\n",
    "        pad_w = max(self.crop_w - img_w, 0)\n",
    "        \n",
    "        #Changed to BORDER_REFLECT From BORDER_CONSTANT\n",
    "        '''\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            img_pad = cv2.copyMakeBorder(image, 0, pad_h, 0, \n",
    "                pad_w, cv2.BORDER_REFLECT, \n",
    "                value=(0.0, 0.0, 0.0))\n",
    "            label_pad = cv2.copyMakeBorder(label, 0, pad_h, 0, \n",
    "                pad_w, cv2.BORDER_REFLECT,\n",
    "                value=(self.ignore_label,))\n",
    "        '''\n",
    "        \n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            img_pad = cv2.copyMakeBorder(image, 0, pad_h, 0, \n",
    "                pad_w, cv2.BORDER_REFLECT, \n",
    "                value=(0.0, 0.0, 0.0))\n",
    "            label_pad = cv2.copyMakeBorder(label, 0, pad_h, 0, \n",
    "                pad_w, cv2.BORDER_REFLECT,\n",
    "                value=(self.ignore_label,))    \n",
    "        \n",
    "        else:\n",
    "            img_pad, label_pad = image, label\n",
    "\n",
    "        img_h, img_w = label_pad.shape\n",
    "        \n",
    "        h_off = 0\n",
    "        w_off = 0\n",
    "        \n",
    "        image = np.asarray(img_pad[h_off : h_off+self.crop_h, w_off : w_off+self.crop_w], np.float32)\n",
    "        label = np.asarray(label_pad[h_off : h_off+self.crop_h, w_off : w_off+self.crop_w], np.float32)\n",
    "        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        if self.is_mirror:\n",
    "            flip = np.random.choice(2) * 2 - 1\n",
    "            image = image[:, :, ::flip]\n",
    "            label = label[:, ::flip]\n",
    "\n",
    "        return image.copy(), label.copy(), np.array(size), name\n",
    "\n",
    "class VOCDataTestSet(data.Dataset):\n",
    "    def __init__(self, root, list_path, crop_size=(505, 505), mean=(128, 128, 128)):\n",
    "        self.root = root\n",
    "        self.list_path = list_path\n",
    "        self.crop_h, self.crop_w = crop_size\n",
    "        self.mean = mean\n",
    "        # self.mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n",
    "        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n",
    "        self.files = [] \n",
    "        # for split in [\"train\", \"trainval\", \"val\"]:\n",
    "        for name in self.img_ids:\n",
    "            img_file = osp.join(self.root, \"JPEGImages/%s.jpg\" % name)\n",
    "            self.files.append({\n",
    "                \"img\": img_file\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        datafiles = self.files[index]\n",
    "        image = cv2.imread(datafiles[\"img\"], cv2.IMREAD_COLOR)\n",
    "        size = image.shape\n",
    "        name = osp.splitext(osp.basename(datafiles[\"img\"]))[0]\n",
    "        image = np.asarray(image, np.float32)\n",
    "        image -= self.mean\n",
    "        \n",
    "        img_h, img_w, _ = image.shape\n",
    "        pad_h = max(self.crop_h - img_h, 0)\n",
    "        pad_w = max(self.crop_w - img_w, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            image = cv2.copyMakeBorder(image, 0, pad_h, 0, \n",
    "                pad_w, cv2.BORDER_REFLECT, \n",
    "                value=(0.0, 0.0, 0.0))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return image, name, size\n",
    "    \n",
    "def binary_gt_convert(output, gt):\n",
    "    #Class independant error\n",
    "    \n",
    "    binary_gt = np.where( gt > 0, 1, 0)\n",
    "    binary_output = np.where( output > 0, 1, 0)\n",
    "    int_gt = np.where(binary_gt-binary_output != 0, 1, 0)\n",
    "    return int_gt\n",
    "\n",
    "\n",
    "def class_gt_convert(output, gt):\n",
    "    #Class dependant error\n",
    "    \n",
    "    class_diff = output - gt                     #correct values will be 0, else is error\n",
    "    int_gt = np.where(class_diff != 0, 1, 0)\n",
    "    return int_gt\n",
    "\n",
    "def class_out_gt_convert(output, gt):\n",
    "    #Multi-class error\n",
    "    \n",
    "    gt = np.where(gt == 255, 0, gt)              #GT with ignored borders\n",
    "    class_diff = output - gt                     #All correct values --> Class_diff will be zero\n",
    "    gt_error_mask = np.where(class_diff == 0, 0, gt)\n",
    "    int_gt = gt_error_mask     \n",
    "    return int_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     64,
     77,
     93,
     115,
     133,
     150,
     153,
     178,
     199,
     211,
     217
    ]
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "IMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Grabs from PascalVOC Development kit structure\n",
    "DATA_DIRECTORY = './data/VOCdevkit/VOC2012'#'../../data/VOCdevkit/voc12'\n",
    "DATA_LIST_PATH = './dataset/list/train_aug.txt' \n",
    "\n",
    "IGNORE_LABEL = 255\n",
    "INPUT_SIZE = '321,321'\n",
    "IS_TRAINING = False\n",
    "\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "NOT_RESTORE_LAST = False\n",
    "NUM_CLASSES = 21\n",
    "NUM_STEPS = 20000\n",
    "POWER = 0.9\n",
    "RANDOM_MIRROR = False\n",
    "RANDOM_SCALE = False\n",
    "RANDOM_SEED = 1234 \n",
    "RESTORE_FROM = './snapshots/VOC12_scenes_20000.pth'                          # Use for training intermediate networks\n",
    "#RESTORE_FROM = './dataset/MS_DeepLab_resnet_pretrained_COCO_init.pth'       # Use for training deeplabv2\n",
    "SAVE_NUM_IMAGES = 2\n",
    "SAVE_PRED_EVERY = 1000\n",
    "SNAPSHOT_DIR = './snapshots/'\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "def get_arguments():\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"data_dir\": DATA_DIRECTORY,\n",
    "    \"data_list\": DATA_LIST_PATH,\n",
    "    \"ignore_label\": IGNORE_LABEL,\n",
    "    \"input_size\": INPUT_SIZE,\n",
    "    \"is_training\": IS_TRAINING,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"momentum\": MOMENTUM,\n",
    "    \"not_restore_last\": NOT_RESTORE_LAST,\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "    \"num_steps\": NUM_STEPS,\n",
    "    \"power\": POWER,\n",
    "    \"random_mirror\": RANDOM_MIRROR,\n",
    "    \"random_scale\": RANDOM_SCALE,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"restore_from\": RESTORE_FROM,\n",
    "    \"save_num_images\": SAVE_NUM_IMAGES,\n",
    "    \"save_pred_every\": SAVE_PRED_EVERY,\n",
    "    \"snapshot_dir\": SNAPSHOT_DIR,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"gpu\": 0\n",
    "    })\n",
    "    \n",
    "    return args\n",
    "\n",
    "args = get_arguments()\n",
    "gpu0 = args.gpu\n",
    "\n",
    "def loss_calc(pred, label):\n",
    "    \"\"\"\n",
    "    This function returns cross entropy loss for semantic segmentation\n",
    "    \"\"\"\n",
    "    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n",
    "    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n",
    "    \n",
    "    label = Variable(label.long()).cuda(gpu0)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=IGNORE_LABEL).cuda(gpu0)\n",
    "    \n",
    "    return criterion(pred, label)\n",
    "\n",
    "def loss_calc_int(pred, label):\n",
    "    \"\"\"\n",
    "    This function returns cross entropy loss for semantic segmentation\n",
    "    \"\"\"\n",
    "    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n",
    "    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n",
    "    \n",
    "    label = Variable(label.long()).cuda(gpu0)\n",
    "    \n",
    "    weights = np.asarray([ 0.85, 0.15])\n",
    "    \n",
    "    tensor_weights = torch.from_numpy(weights).float().cuda(gpu0)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight = tensor_weights, ignore_index=IGNORE_LABEL).cuda(gpu0)\n",
    "    \n",
    "    return criterion(pred, label)\n",
    "\n",
    "def weighted_cross_entropy_loss(prediction, label):   #Taken from ~~ https://github.com/meteorshowers/hed-pytorch/blob/master/functions.py ~~\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "    \n",
    "    label = Variable(label.long()).cuda(gpu0)\n",
    "    nch = prediction.shape[1]\n",
    "    label[label >= nch] = 0\n",
    "    \n",
    "    cost = criterion(prediction, label)\n",
    "    \n",
    "    mask = (label != 0).float()\n",
    "    num_positive = torch.sum(mask).float()\n",
    "    num_negative = mask.numel() - num_positive\n",
    "    \n",
    "    mask[mask == 1] = 0.9\n",
    "    mask[mask == 0] = 0.1\n",
    "    \n",
    "    \n",
    "    cost = torch.mul(cost, mask)\n",
    "\n",
    "    return torch.sum(cost)\n",
    "\n",
    "def SP_Loss_calc(new_model, old_param_list):\n",
    "    new_param_list = []\n",
    "    \n",
    "    for param in new_model.parameters():\n",
    "        new_param_list.append(param.data)\n",
    "    \n",
    "    param_diff = []\n",
    "    count = 0\n",
    "    for i in new_param_list:\n",
    "        param_diff.append(i - old_param_list[count])\n",
    "        count += 1\n",
    "\n",
    "    for j in range(len(param_diff)):\n",
    "        param_diff[j] = param_diff[j].norm()\n",
    "        \n",
    "    loss = sum(param_diff)\n",
    "    return loss.item()\n",
    "\n",
    "def multiclass_weight_loss_calc(pred, label):\n",
    "    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n",
    "    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n",
    "    \n",
    "    unique, counts = np.unique(label, return_counts=True)\n",
    "    label = Variable(label.long()).cuda(gpu0)\n",
    "\n",
    "    manual_weights = np.asarray([0.85, 0.15, 0.15, 0.15 , 0.15, 0.15, 0.15, \n",
    "                      0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15,\n",
    "                      0.15, 0.15, 0.15, 0.15,0.15, 0.15])\n",
    "    \n",
    "    tensor_weight = torch.from_numpy(manual_weights).float().cuda(gpu0)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss(weight = tensor_weight)\n",
    "    \n",
    "    return criterion(pred, label)\n",
    "\n",
    "def lr_poly(base_lr, iter, max_iter, power):\n",
    "    return base_lr*((1-float(iter)/max_iter)**(power))\n",
    "\n",
    "def get_1x_lr_params_NOscale(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters of the net except for \n",
    "    the last classification layer. Note that for each batchnorm layer, \n",
    "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return \n",
    "    any batchnorm parameter\n",
    "    \"\"\"\n",
    "    b = []\n",
    "\n",
    "    b.append(model.conv1)\n",
    "    b.append(model.bn1)\n",
    "    b.append(model.layer1)\n",
    "    b.append(model.layer2)\n",
    "    b.append(model.layer3)\n",
    "    b.append(model.layer4)\n",
    "\n",
    "    \n",
    "    for i in range(len(b)):\n",
    "        for j in b[i].modules():\n",
    "            jj = 0\n",
    "            for k in j.parameters():\n",
    "                jj+=1\n",
    "                if k.requires_grad:\n",
    "                    yield k\n",
    "                \n",
    "def get_1x_lr_params_NOscale_int(model): \n",
    "    \"\"\"\n",
    "    This generator returns all the parameters of the net except for \n",
    "    the last classification layer. Note that for each batchnorm layer, \n",
    "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return \n",
    "    any batchnorm parameter\n",
    "    \"\"\"\n",
    "    b = []\n",
    "\n",
    "    b.append(model.layer1)\n",
    "    b.append(model.bn1)\n",
    "    b.append(model.predict)\n",
    "    \n",
    "    for i in range(len(b)):\n",
    "        for j in b[i].modules():\n",
    "            jj = 0\n",
    "            for k in j.parameters():\n",
    "                jj+=1\n",
    "                if k.requires_grad:\n",
    "                    yield k\n",
    "\n",
    "def get_10x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters for the last layer of the net,\n",
    "    which does the classification of pixel into classes\n",
    "    \"\"\"\n",
    "    b = []\n",
    "    b.append(model.layer5.parameters())\n",
    "\n",
    "    for j in range(len(b)):\n",
    "        for i in b[j]:\n",
    "            yield i          \n",
    "            \n",
    "def adjust_learning_rate(optimizer, i_iter):\n",
    "    \"\"\"Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs\"\"\"\n",
    "    lr = lr_poly(args.learning_rate, i_iter, args.num_steps, args.power)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    optimizer.param_groups[1]['lr'] = lr * 10\n",
    "    \n",
    "def adjust_learning_rate_int(optimizer, i_iter):\n",
    "    \"\"\"Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs\"\"\"\n",
    "    lr = lr_poly(args.learning_rate, i_iter, args.num_steps, args.power)\n",
    "    optimizer.param_groups[0]['lr'] = lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  0 of 20000 completed, loss =  3.0471473\n",
      "iter =  1 of 20000 completed, loss =  3.0501933\n",
      "iter =  2 of 20000 completed, loss =  3.0464838\n",
      "iter =  3 of 20000 completed, loss =  3.0261605\n",
      "iter =  4 of 20000 completed, loss =  3.028804\n",
      "iter =  5 of 20000 completed, loss =  3.0427897\n",
      "iter =  6 of 20000 completed, loss =  3.0559728\n",
      "iter =  7 of 20000 completed, loss =  3.0456262\n",
      "iter =  8 of 20000 completed, loss =  3.0123982\n",
      "iter =  9 of 20000 completed, loss =  3.0448115\n",
      "iter =  10 of 20000 completed, loss =  3.0578582\n",
      "iter =  11 of 20000 completed, loss =  3.0502415\n",
      "iter =  12 of 20000 completed, loss =  3.0336628\n",
      "iter =  13 of 20000 completed, loss =  3.033785\n",
      "iter =  14 of 20000 completed, loss =  3.0534456\n",
      "iter =  15 of 20000 completed, loss =  3.035496\n",
      "iter =  16 of 20000 completed, loss =  3.018478\n",
      "iter =  17 of 20000 completed, loss =  3.0436037\n",
      "iter =  18 of 20000 completed, loss =  3.0281794\n",
      "iter =  19 of 20000 completed, loss =  3.0229006\n",
      "iter =  20 of 20000 completed, loss =  3.0237885\n",
      "iter =  21 of 20000 completed, loss =  3.0292778\n",
      "iter =  22 of 20000 completed, loss =  3.0408509\n",
      "iter =  23 of 20000 completed, loss =  3.0366728\n",
      "iter =  24 of 20000 completed, loss =  2.9904728\n",
      "iter =  25 of 20000 completed, loss =  3.0272343\n",
      "iter =  26 of 20000 completed, loss =  3.0317953\n",
      "iter =  27 of 20000 completed, loss =  3.0468426\n",
      "iter =  28 of 20000 completed, loss =  3.0308363\n",
      "iter =  29 of 20000 completed, loss =  3.0129285\n",
      "iter =  30 of 20000 completed, loss =  3.027537\n",
      "iter =  31 of 20000 completed, loss =  3.0825312\n",
      "iter =  32 of 20000 completed, loss =  3.017948\n",
      "iter =  33 of 20000 completed, loss =  3.021698\n",
      "iter =  34 of 20000 completed, loss =  3.0292602\n",
      "iter =  35 of 20000 completed, loss =  3.0731297\n",
      "iter =  36 of 20000 completed, loss =  3.020649\n",
      "iter =  37 of 20000 completed, loss =  3.0143414\n",
      "iter =  38 of 20000 completed, loss =  3.0351505\n",
      "iter =  39 of 20000 completed, loss =  3.0238378\n",
      "iter =  40 of 20000 completed, loss =  3.0217083\n",
      "iter =  41 of 20000 completed, loss =  3.0145116\n",
      "iter =  42 of 20000 completed, loss =  3.0327897\n",
      "iter =  43 of 20000 completed, loss =  2.9956608\n",
      "iter =  44 of 20000 completed, loss =  3.0148773\n",
      "iter =  45 of 20000 completed, loss =  3.024648\n",
      "iter =  46 of 20000 completed, loss =  3.0153863\n",
      "iter =  47 of 20000 completed, loss =  3.0117292\n",
      "iter =  48 of 20000 completed, loss =  3.0093098\n",
      "iter =  49 of 20000 completed, loss =  3.014025\n",
      "iter =  50 of 20000 completed, loss =  3.0031307\n",
      "iter =  51 of 20000 completed, loss =  3.0066915\n",
      "iter =  52 of 20000 completed, loss =  3.0117147\n",
      "iter =  53 of 20000 completed, loss =  3.0131168\n",
      "iter =  54 of 20000 completed, loss =  3.0315783\n",
      "iter =  55 of 20000 completed, loss =  3.0046518\n",
      "iter =  56 of 20000 completed, loss =  3.00978\n",
      "iter =  57 of 20000 completed, loss =  3.0026553\n",
      "iter =  58 of 20000 completed, loss =  3.0124545\n",
      "iter =  59 of 20000 completed, loss =  3.004543\n",
      "iter =  60 of 20000 completed, loss =  2.9984705\n",
      "iter =  61 of 20000 completed, loss =  3.0096984\n",
      "iter =  62 of 20000 completed, loss =  3.0028923\n",
      "iter =  63 of 20000 completed, loss =  3.0058389\n",
      "iter =  64 of 20000 completed, loss =  2.9879966\n",
      "iter =  65 of 20000 completed, loss =  3.0086071\n",
      "iter =  66 of 20000 completed, loss =  2.9858549\n",
      "iter =  67 of 20000 completed, loss =  3.02994\n",
      "iter =  68 of 20000 completed, loss =  2.9913335\n",
      "iter =  69 of 20000 completed, loss =  3.010887\n",
      "iter =  70 of 20000 completed, loss =  2.99679\n",
      "iter =  71 of 20000 completed, loss =  2.9957395\n",
      "iter =  72 of 20000 completed, loss =  3.0206604\n",
      "iter =  73 of 20000 completed, loss =  3.0004687\n",
      "iter =  74 of 20000 completed, loss =  3.0084202\n",
      "iter =  75 of 20000 completed, loss =  2.995746\n",
      "iter =  76 of 20000 completed, loss =  2.9986928\n",
      "iter =  77 of 20000 completed, loss =  2.9725883\n",
      "iter =  78 of 20000 completed, loss =  2.9847057\n",
      "iter =  79 of 20000 completed, loss =  3.0117452\n",
      "iter =  80 of 20000 completed, loss =  3.0095875\n",
      "iter =  81 of 20000 completed, loss =  2.9831045\n",
      "iter =  82 of 20000 completed, loss =  3.003482\n",
      "iter =  83 of 20000 completed, loss =  2.9805188\n",
      "iter =  84 of 20000 completed, loss =  2.9911623\n",
      "iter =  85 of 20000 completed, loss =  2.9918835\n",
      "iter =  86 of 20000 completed, loss =  3.05526\n",
      "iter =  87 of 20000 completed, loss =  2.9987235\n",
      "iter =  88 of 20000 completed, loss =  2.9899368\n",
      "iter =  89 of 20000 completed, loss =  3.0014255\n",
      "iter =  90 of 20000 completed, loss =  2.999009\n",
      "iter =  91 of 20000 completed, loss =  2.9749932\n",
      "iter =  92 of 20000 completed, loss =  2.998743\n",
      "iter =  93 of 20000 completed, loss =  3.0004508\n",
      "iter =  94 of 20000 completed, loss =  2.9746387\n",
      "iter =  95 of 20000 completed, loss =  2.9803033\n",
      "iter =  96 of 20000 completed, loss =  2.9960475\n",
      "iter =  97 of 20000 completed, loss =  2.989259\n",
      "iter =  98 of 20000 completed, loss =  2.9983535\n",
      "iter =  99 of 20000 completed, loss =  3.013441\n",
      "iter =  100 of 20000 completed, loss =  3.0028853\n",
      "iter =  101 of 20000 completed, loss =  2.9734082\n",
      "iter =  102 of 20000 completed, loss =  2.9860709\n",
      "iter =  103 of 20000 completed, loss =  2.980638\n",
      "iter =  104 of 20000 completed, loss =  2.989358\n",
      "iter =  105 of 20000 completed, loss =  2.9830418\n",
      "iter =  106 of 20000 completed, loss =  2.9738646\n",
      "iter =  107 of 20000 completed, loss =  2.993704\n",
      "iter =  108 of 20000 completed, loss =  2.994087\n",
      "iter =  109 of 20000 completed, loss =  2.977979\n",
      "iter =  110 of 20000 completed, loss =  2.9667373\n",
      "iter =  111 of 20000 completed, loss =  2.9737475\n",
      "iter =  112 of 20000 completed, loss =  2.9896777\n",
      "iter =  113 of 20000 completed, loss =  2.9688594\n",
      "iter =  114 of 20000 completed, loss =  2.9922993\n",
      "iter =  115 of 20000 completed, loss =  2.9956434\n",
      "iter =  116 of 20000 completed, loss =  2.964394\n",
      "iter =  117 of 20000 completed, loss =  2.983192\n",
      "iter =  118 of 20000 completed, loss =  2.9663353\n",
      "iter =  119 of 20000 completed, loss =  2.9829915\n",
      "iter =  120 of 20000 completed, loss =  2.9519064\n",
      "iter =  121 of 20000 completed, loss =  2.9854455\n",
      "iter =  122 of 20000 completed, loss =  2.9671881\n",
      "iter =  123 of 20000 completed, loss =  2.9559057\n",
      "iter =  124 of 20000 completed, loss =  2.9652598\n",
      "iter =  125 of 20000 completed, loss =  2.9559479\n",
      "iter =  126 of 20000 completed, loss =  2.9693348\n",
      "iter =  127 of 20000 completed, loss =  2.9966986\n",
      "iter =  128 of 20000 completed, loss =  2.9765623\n",
      "iter =  129 of 20000 completed, loss =  2.966972\n",
      "iter =  130 of 20000 completed, loss =  2.9643784\n",
      "iter =  131 of 20000 completed, loss =  2.9546363\n",
      "iter =  132 of 20000 completed, loss =  2.9631753\n",
      "iter =  133 of 20000 completed, loss =  2.964595\n",
      "iter =  134 of 20000 completed, loss =  2.9643407\n",
      "iter =  135 of 20000 completed, loss =  2.9661949\n",
      "iter =  136 of 20000 completed, loss =  2.96947\n",
      "iter =  137 of 20000 completed, loss =  2.9548028\n",
      "iter =  138 of 20000 completed, loss =  2.94334\n",
      "iter =  139 of 20000 completed, loss =  3.0124035\n",
      "iter =  140 of 20000 completed, loss =  2.9423919\n",
      "iter =  141 of 20000 completed, loss =  2.9678476\n",
      "iter =  142 of 20000 completed, loss =  2.9653642\n",
      "iter =  143 of 20000 completed, loss =  2.953383\n",
      "iter =  144 of 20000 completed, loss =  2.972795\n",
      "iter =  145 of 20000 completed, loss =  2.957629\n",
      "iter =  146 of 20000 completed, loss =  2.955058\n",
      "iter =  147 of 20000 completed, loss =  2.9515398\n",
      "iter =  148 of 20000 completed, loss =  2.9447057\n",
      "iter =  149 of 20000 completed, loss =  2.9502952\n",
      "iter =  150 of 20000 completed, loss =  2.963093\n",
      "iter =  151 of 20000 completed, loss =  2.9597795\n",
      "iter =  152 of 20000 completed, loss =  2.9597871\n",
      "iter =  153 of 20000 completed, loss =  2.9631639\n",
      "iter =  154 of 20000 completed, loss =  2.99201\n",
      "iter =  155 of 20000 completed, loss =  2.9702728\n",
      "iter =  156 of 20000 completed, loss =  2.9419286\n",
      "iter =  157 of 20000 completed, loss =  2.9466248\n",
      "iter =  158 of 20000 completed, loss =  2.9549823\n",
      "iter =  159 of 20000 completed, loss =  2.9609811\n",
      "iter =  160 of 20000 completed, loss =  2.9553497\n",
      "iter =  161 of 20000 completed, loss =  2.9427266\n",
      "iter =  162 of 20000 completed, loss =  2.9589741\n",
      "iter =  163 of 20000 completed, loss =  2.9311697\n",
      "iter =  164 of 20000 completed, loss =  2.9547198\n",
      "iter =  165 of 20000 completed, loss =  2.9489758\n",
      "iter =  166 of 20000 completed, loss =  2.9417033\n",
      "iter =  167 of 20000 completed, loss =  2.9503803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  168 of 20000 completed, loss =  2.948048\n",
      "iter =  169 of 20000 completed, loss =  2.9197226\n",
      "iter =  170 of 20000 completed, loss =  2.9320104\n",
      "iter =  171 of 20000 completed, loss =  2.948008\n",
      "iter =  172 of 20000 completed, loss =  2.951106\n",
      "iter =  173 of 20000 completed, loss =  2.9519012\n",
      "iter =  174 of 20000 completed, loss =  2.9371107\n",
      "iter =  175 of 20000 completed, loss =  2.9504938\n",
      "iter =  176 of 20000 completed, loss =  2.9611397\n",
      "iter =  177 of 20000 completed, loss =  2.9397905\n",
      "iter =  178 of 20000 completed, loss =  2.9327753\n",
      "iter =  179 of 20000 completed, loss =  2.9478753\n",
      "iter =  180 of 20000 completed, loss =  2.942185\n",
      "iter =  181 of 20000 completed, loss =  2.938369\n",
      "iter =  182 of 20000 completed, loss =  2.9352193\n",
      "iter =  183 of 20000 completed, loss =  2.9294615\n",
      "iter =  184 of 20000 completed, loss =  2.9347332\n",
      "iter =  185 of 20000 completed, loss =  2.9237163\n",
      "iter =  186 of 20000 completed, loss =  2.936314\n",
      "iter =  187 of 20000 completed, loss =  2.9281528\n",
      "iter =  188 of 20000 completed, loss =  2.9128797\n",
      "iter =  189 of 20000 completed, loss =  2.9657078\n",
      "iter =  190 of 20000 completed, loss =  2.9283445\n",
      "iter =  191 of 20000 completed, loss =  2.9309583\n",
      "iter =  192 of 20000 completed, loss =  2.928692\n",
      "iter =  193 of 20000 completed, loss =  2.9315944\n",
      "iter =  194 of 20000 completed, loss =  2.942169\n",
      "iter =  195 of 20000 completed, loss =  2.8968973\n",
      "iter =  196 of 20000 completed, loss =  2.925191\n",
      "iter =  197 of 20000 completed, loss =  2.9405062\n",
      "iter =  198 of 20000 completed, loss =  2.9183836\n",
      "iter =  199 of 20000 completed, loss =  2.924772\n",
      "iter =  200 of 20000 completed, loss =  2.906083\n",
      "iter =  201 of 20000 completed, loss =  2.9428668\n",
      "iter =  202 of 20000 completed, loss =  2.9290788\n",
      "iter =  203 of 20000 completed, loss =  2.9157028\n",
      "iter =  204 of 20000 completed, loss =  2.9400163\n",
      "iter =  205 of 20000 completed, loss =  2.9173412\n",
      "iter =  206 of 20000 completed, loss =  2.9326887\n",
      "iter =  207 of 20000 completed, loss =  2.9316018\n",
      "iter =  208 of 20000 completed, loss =  2.904591\n",
      "iter =  209 of 20000 completed, loss =  2.9228275\n",
      "iter =  210 of 20000 completed, loss =  2.9178\n",
      "iter =  211 of 20000 completed, loss =  2.9036365\n",
      "iter =  212 of 20000 completed, loss =  2.9062822\n",
      "iter =  213 of 20000 completed, loss =  2.9130552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-2:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  214 of 20000 completed, loss =  2.920473\n",
      "iter =  215 of 20000 completed, loss =  2.9138086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-5-dcbad62efa25>\", line 46, in __getitem__\n",
      "    image -= self.mean\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/home/m3kowal/anaconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-773aac05821b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m      \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-773aac05821b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0madjust_learning_rate_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f32ea676dc66>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f32ea676dc66>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     )\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING SUPERVISOR NETWORKS\n",
    "def main():\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(args.gpu)\n",
    "    h, w = map(int, args.input_size.split(','))\n",
    "    input_size = (h, w)\n",
    "\n",
    "    cudnn.enabled = True\n",
    "    \n",
    "    layer = 99\n",
    "    \n",
    "    # Create networks\n",
    "    model = Res_Deeplab(num_classes=args.num_classes)\n",
    "    #int_model = Decoder_Binary(input_size_list[layer])                                         #input_size_list[layer] defines input size for mid layer\n",
    "    #int_model = Decoder_Multiclass_Weighting(input_size_list[layer], num_classes = NUM_CLASSES)  \n",
    "    int_model = Decoder_Multiclass_Weighting_Deep(input_size_list[layer], num_classes= NUM_CLASSES)\n",
    "\n",
    "    gpu0 = args.gpu\n",
    "\n",
    "    saved_state_dict = torch.load('./snapshots/VOC12_scenes_20000.pth')\n",
    "    \n",
    "    '''\n",
    "    #Loading and removing extra term infront of layer names if neccessary\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in saved_state_dict.items():\n",
    "        name = k[6:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(saved_state_dict)\n",
    "    \n",
    "    model.eval()\n",
    "    model.cuda(gpu0)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    int_model.train()\n",
    "    int_model.cuda(gpu0)\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if not os.path.exists('./Int_Snapshots/'):\n",
    "        os.makedirs('./Int_Snapshots/')\n",
    "\n",
    "\n",
    "    trainloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, max_iters=args.num_steps*args.batch_size, crop_size=input_size, scale=args.random_scale, mirror=args.random_mirror, mean=IMG_MEAN), \n",
    "                    batch_size=1, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "    \n",
    "    optimizer = optim.SGD(params = get_1x_lr_params_NOscale_int(int_model), lr=args.learning_rate, momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    interp = nn.Upsample(size=input_size, mode='bilinear', align_corners=True)\n",
    "\n",
    "\n",
    "    for i_iter, batch in enumerate(trainloader):\n",
    "        images, labels, size, name = batch\n",
    "        \n",
    "        size = size.numpy()[0]\n",
    "        \n",
    "        global activations\n",
    "        activations = []\n",
    "\n",
    "        images = Variable(images).cuda(gpu0)\n",
    "        optimizer.zero_grad()\n",
    "        adjust_learning_rate_int(optimizer, i_iter)\n",
    "        output = interp(model(images)).cpu().data[0].numpy()\n",
    "        \n",
    "        gt = np.asarray(labels[0].numpy(), dtype=np.int)\n",
    "        output = output.transpose(1,2,0)\n",
    "        \n",
    "        output = np.asarray(np.argmax(output, axis=2), dtype=np.int)\n",
    "        \n",
    "\n",
    "        #int_gt = binary_gt_convert(output, gt)       #Class independant binary error prediction case\n",
    "        #int_gt = class_gt_convert(output, gt)        #Class dependant binary error prediction case\n",
    "        int_gt = class_out_gt_convert(output, gt)     #Multi-class error prediction case\n",
    "        \n",
    "        #Reshaping to [1, 321, 321]\n",
    "        int_gt = int_gt[np.newaxis,:,:]  \n",
    "        int_gt = torch.from_numpy(int_gt)    \n",
    "\n",
    "        int_output = interp(int_model(activations[layer]))      #Output of intermediate layer\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Different loss functions for multiclass vs binary error\n",
    "        loss = multiclass_weight_loss_calc(int_output, int_gt)\n",
    "        #loss = weighted_cross_entropy_loss(int_output, int_gt)        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "          \n",
    "            \n",
    "        print('iter = ', i_iter, 'of', args.num_steps,'completed, loss = ', loss.data.cpu().numpy())\n",
    "\n",
    "        if i_iter >= args.num_steps-1:\n",
    "            print( 'save model ...')\n",
    "            torch.save(int_model.state_dict(),osp.join('./Int_Snapshots/', 'NAME_OF_SUPERVISOR' + str(LEARNING_RATE) + str(args.num_steps)+'.pth'))\n",
    "            break\n",
    "\n",
    "        if i_iter % args.save_pred_every == 0 and i_iter!=0:\n",
    "            print('taking snapshot ...')\n",
    "            torch.save(int_model.state_dict(),osp.join('./Int_Snapshots/', 'NAME_OF_SUPERVISOR' + str(LEARNING_RATE) + str(i_iter)+'.pth'))\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    print(end-start,'seconds')\n",
    "\n",
    "if __name__ == '__main__': \n",
    "     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TRAINING AND FINE-TUNING THE STUDENT\n",
    "\n",
    "#Defining source model for L2-SP loss\n",
    "source_model = Res_Deeplab(num_classes=args.num_classes)\n",
    "source_saved_state = torch.load('./snapshots/VOC12_scenes_20000.pth')\n",
    "source_model.load_state_dict(source_saved_state)  \n",
    "source_model.eval()\n",
    "source_model.cuda(gpu0)\n",
    "old_param_list = []\n",
    "    \n",
    "for param in source_model.parameters():\n",
    "    old_param_list.append(param.data)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Create the model and start the training.\"\"\"\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(args.gpu)\n",
    "    h, w = map(int, args.input_size.split(','))\n",
    "    input_size = (h, w)\n",
    "\n",
    "    cudnn.enabled = True\n",
    "    layer = 99     #THIS DEFINES THE LAYER THAT THE SUPERVISOR GRABS ACTIVATIONS FROM\n",
    "    \n",
    "    # Create networks\n",
    "    model = Res_Deeplab(num_classes=args.num_classes)\n",
    "    \n",
    "    int_model = Decoder_Binary(input_size_list[layer])\n",
    "    #int_model = Decoder_Multiclass_Weighting(input_size_list[layer], num_classes = NUM_CLASSES)       #input_size_list[layer] defines input size for mid layer\n",
    "\n",
    "    saved_state_dict = torch.load(args.restore_from)\n",
    "    int_saved_state_dict = torch.load('./Int_Snapshots/Binary_Error/REFLECT_PADDING/class_dependant/class_dep_lay90_lr2.5e-0510000.pth')\n",
    "    \n",
    "    \n",
    "    new_params = model.state_dict().copy()\n",
    "    for i in saved_state_dict:\n",
    "        #Scale.layer5.conv2d_list.3.weight\n",
    "        i_parts = i.split('.')\n",
    "        # print i_parts\n",
    "        if not args.num_classes == 21 or not i_parts[1]=='layer5':\n",
    "            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n",
    "            \n",
    "    model.load_state_dict(saved_state_dict)                            #For training from VOC weights\n",
    "    #model.load_state_dict(new_params)                                 #For training from COCO pre-trained weights\n",
    "    model.train()\n",
    "    model.cuda(gpu0)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    ct = 0\n",
    "    for child in model.children():\n",
    "        if ct < 8:\n",
    "            for param in child.parameters():                 #Uncomment this to freeze certain layers of the student during the fine-tuning process\n",
    "                param.requires_grad = False\n",
    "        ct += 1\n",
    "    '''\n",
    "    \n",
    "    # Create supervisor\n",
    "    int_model.load_state_dict(int_saved_state_dict)\n",
    "    int_model.eval()\n",
    "    int_model.cuda(gpu0)\n",
    "    \n",
    "    \n",
    "    #Freeze weights in supervisor network\n",
    "    for child in int_model.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if not os.path.exists(args.snapshot_dir):\n",
    "        os.makedirs(args.snapshot_dir)\n",
    "\n",
    "\n",
    "    trainloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, max_iters=args.num_steps*args.batch_size, crop_size=input_size, \n",
    "                    scale=args.random_scale, mirror=args.random_mirror, mean=IMG_MEAN), \n",
    "                    batch_size=args.batch_size, shuffle=True, num_workers=5, pin_memory=True)\n",
    "\n",
    "    optimizer = optim.SGD([{'params': get_1x_lr_params_NOscale(model), 'lr': args.learning_rate }, \n",
    "                {'params': get_10x_lr_params(model), 'lr': 10*args.learning_rate}], \n",
    "                lr=args.learning_rate, momentum=args.momentum ,weight_decay=args.weight_decay)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    interp = nn.Upsample(size=input_size, mode='bilinear', align_corners=True)\n",
    "\n",
    "    \n",
    "    for i_iter, batch in enumerate(trainloader):\n",
    "        images, labels, size, name = batch\n",
    "        \n",
    "        size = size.numpy()[0]\n",
    "        \n",
    "        global activations\n",
    "        activations = []\n",
    "\n",
    "        #------------------------------------------------------------------------\n",
    "        \n",
    "        images = Variable(images).cuda(gpu0)\n",
    "        optimizer.zero_grad()\n",
    "        adjust_learning_rate(optimizer, i_iter)\n",
    "        pred = interp(model(images))\n",
    "        \n",
    "        output = interp(model(images)).cpu().data[0].numpy()\n",
    "        \n",
    "        gt = np.asarray(labels[0].numpy(), dtype=np.int)\n",
    "        output = pred.cpu().data[0].numpy().transpose(1,2,0)\n",
    "        output = np.asarray(np.argmax(output, axis=2), dtype=np.int)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Fine tuning was only done using the binary class-dependant error\n",
    "        int_gt = binary_gt_convert(output, gt)    \n",
    "        \n",
    "        int_gt = int_gt[np.newaxis,:,:]  \n",
    "        int_gt = torch.from_numpy(int_gt)\n",
    "        \n",
    "        int_output = interp(int_model(activations[layer]))\n",
    "        \n",
    "        \n",
    "        EG_reg = int_output.cpu().data[0].numpy()\n",
    "        EG_reg = EG_reg[:,:size[0],:size[1]]\n",
    "        EG_reg = EG_reg.transpose(1,2,0)\n",
    "        EG_reg = np.asarray(np.argmax(EG_reg, axis=2), dtype=np.int)\n",
    "        EG_reg = np.count_nonzero(EG_reg)/ EG_reg.size\n",
    "        \n",
    "        egloss_weight = 1\n",
    "        alpha = 1\n",
    "        \n",
    "        loss1 = loss_calc(pred, labels)\n",
    "                \n",
    "        loss2 = egloss_weight*loss_calc_int(int_output, int_gt)\n",
    "        SP_Loss = (alpha/2)*SP_Loss_calc(model, old_param_list)\n",
    "        \n",
    "        loss = loss1 + EG_reg + SP_Loss + loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        print('iter = ', i_iter, 'of', args.num_steps,'completed, loss = ', loss.data.cpu().numpy())\n",
    "        \n",
    "        if i_iter >= args.num_steps-1:\n",
    "            print( 'save model ...')\n",
    "            torch.save(model.state_dict(),osp.join(args.snapshot_dir, 'NAME_OF_FINETUNED_MODEL' + str(LEARNING_RATE) +str(args.num_steps)+'.pth'))\n",
    "            break\n",
    "\n",
    "        if i_iter % args.save_pred_every == 0 and i_iter!=0:\n",
    "            print('taking snapshot ...')\n",
    "            torch.save(model.state_dict(),osp.join(args.snapshot_dir, 'NAME_OF_FINETUNED_MODEL' + str(LEARNING_RATE) +str(i_iter)+'.pth'))     \n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    print(end-start,'seconds')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     1,
     60,
     66,
     70
    ]
   },
   "outputs": [],
   "source": [
    "# Metric setup\n",
    "def _pickle_method(m):\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copyreg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "class ConfusionMatrix(object):\n",
    "\n",
    "    def __init__(self, nclass, classes=None):\n",
    "        self.nclass = nclass\n",
    "        self.classes = classes\n",
    "        self.M = np.zeros((nclass, nclass))\n",
    "\n",
    "    def add(self, gt, pred):\n",
    "        assert(np.max(pred) <= self.nclass)\n",
    "        assert(len(gt) == len(pred))\n",
    "        for i in range(len(gt)):\n",
    "            if not gt[i] == 255:\n",
    "                self.M[gt[i], pred[i]] += 1.0\n",
    "\n",
    "    def addM(self, matrix):\n",
    "        assert(matrix.shape == self.M.shape)\n",
    "        self.M += matrix\n",
    "\n",
    "    def __str__(self):\n",
    "        pass\n",
    "\n",
    "    def recall(self):\n",
    "        recall = 0.0\n",
    "        for i in range(self.nclass):\n",
    "            recall += self.M[i, i] / np.sum(self.M[:, i])\n",
    "\n",
    "        return recall/self.nclass\n",
    "\n",
    "    def accuracy(self):\n",
    "        accuracy = 0.0\n",
    "        for i in range(self.nclass):\n",
    "            accuracy += self.M[i, i] / np.sum(self.M[i, :])\n",
    "\n",
    "        return accuracy/self.nclass\n",
    "\n",
    "    def jaccard(self):\n",
    "        jaccard = 0.0\n",
    "        jaccard_perclass = []\n",
    "        for i in range(self.nclass):\n",
    "            jaccard_perclass.append(self.M[i, i] / (np.sum(self.M[i, :]) + np.sum(self.M[:, i]) - self.M[i, i]))\n",
    "\n",
    "        return np.sum(jaccard_perclass)/len(jaccard_perclass), jaccard_perclass, self.M\n",
    "\n",
    "    def generateM(self, item):\n",
    "        gt, pred = item\n",
    "        m = np.zeros((self.nclass, self.nclass))\n",
    "        assert(len(gt) == len(pred))\n",
    "        for i in range(len(gt)):\n",
    "            if gt[i] < self.nclass: #and pred[i] < self.nclass:\n",
    "                m[gt[i], pred[i]] += 1.0\n",
    "        return m\n",
    "\n",
    "def confidence_score(pred, gt):\n",
    "    error_ones = np.where(pred-gt != 0, 1, 0)\n",
    "    num_errors = np.count_nonzero(error_ones == 1)\n",
    "    error_percentage = num_errors / gt.size\n",
    "    return (1-error_percentage)\n",
    "\n",
    "def binary_IOU(pred, gt):\n",
    "    IOU = jaccard_similarity_score(pred, gt)\n",
    "    return IOU\n",
    "\n",
    "def multiclass_IOU(pred, gt):\n",
    "    pred = np.asarray(pred).astype(np.bool)\n",
    "    gt = np.asarray(gt).astype(np.bool)\n",
    "\n",
    "    intersection = np.logical_and(pred, gt)\n",
    "\n",
    "    union = np.logical_or(pred, gt)\n",
    "\n",
    "    return intersection.sum() / float(union.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     41,
     56,
     88
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluation setup\n",
    "IMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n",
    "\n",
    "DATA_DIRECTORY = 'data/VOCdevkit/VOC2012'\n",
    "DATA_LIST_PATH = './dataset/list/val.txt'\n",
    "IGNORE_LABEL = 255\n",
    "NUM_CLASSES = 21\n",
    "NUM_STEPS = 1449                                         # Number of images in the validation set. is 1449\n",
    "RESTORE_FROM = './snapshots/VOC12_scenes_20000.pth'      # Load the student parameters here\n",
    "\n",
    "def get_arguments():\n",
    "\n",
    "    args = easydict.EasyDict({\n",
    "    \"data_dir\": DATA_DIRECTORY,\n",
    "    \"data_list\": DATA_LIST_PATH,\n",
    "    \"ignore_label\": IGNORE_LABEL,\n",
    "    \"num_classes\": NUM_CLASSES,\n",
    "    \"restore_from\": RESTORE_FROM,\n",
    "    \"gpu\": 0\n",
    "    })\n",
    "    \n",
    "    return args\n",
    "\n",
    "def get_iou(data_list, class_num, save_path=None):\n",
    "\n",
    "    ConfM = ConfusionMatrix(class_num)\n",
    "    f = ConfM.generateM\n",
    "    pool = Pool() \n",
    "    m_list = pool.map(f, data_list)\n",
    "    pool.close() \n",
    "    pool.join() \n",
    "    \n",
    "    for m in m_list:\n",
    "        ConfM.addM(m)\n",
    "\n",
    "    aveJ, j_list, M = ConfM.jaccard()\n",
    "    print('meanIOU: ' + str(aveJ) + '\\n')\n",
    "            \n",
    "def show_all(gt, pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import colors\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    classes = np.array(('background',  # always index 0\n",
    "               'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                         'cow', 'diningtable', 'dog', 'horse',\n",
    "                         'motorbike', 'person', 'pottedplant',\n",
    "                         'sheep', 'sofa', 'train', 'tvmonitor'))\n",
    "    \n",
    "    colormap = [(0,0,0),(0.5,0,0),(0,0.5,0),(0.5,0.5,0),(0,0,0.5),(0.5,0,0.5),(0,0.5,0.5), \n",
    "                    (0.5,0.5,0.5),(0.25,0,0),(0.75,0,0),(0.25,0.5,0),(0.75,0.5,0),(0.25,0,0.5), \n",
    "                    (0.75,0,0.5),(0.25,0.5,0.5),(0.75,0.5,0.5),(0,0.25,0),(0.5,0.25,0),(0,0.75,0), \n",
    "                    (0.5,0.75,0),(0,0.25,0.5)]\n",
    "    \n",
    "    cmap = colors.ListedColormap(colormap)\n",
    "    bounds=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    ax1.set_title('Groundtruth')\n",
    "    ax1.imshow(gt, cmap=cmap, norm=norm)\n",
    "\n",
    "    ax2.set_title('Output')\n",
    "    ax2.imshow(pred, cmap=cmap, norm=norm)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def show_all_binary(gt, pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import colors\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    classes = np.array(('background',  # always index 0\n",
    "               'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                         'cow', 'diningtable', 'dog', 'horse',\n",
    "                         'motorbike', 'person', 'pottedplant',\n",
    "                         'sheep', 'sofa', 'train', 'tvmonitor'))\n",
    "    colormap = [(0,0,0),'yellow',(0,0.5,0),(0.5,0.5,0),(0,0,0.5),(0.5,0,0.5),(0,0.5,0.5), \n",
    "                    (0.5,0.5,0.5),(0.25,0,0),(0.75,0,0),(0.25,0.5,0),(0.75,0.5,0),(0.25,0,0.5), \n",
    "                    (0.75,0,0.5),(0.25,0.5,0.5),(0.75,0.5,0.5),(0,0.25,0),(0.5,0.25,0),(0,0.75,0), \n",
    "                    (0.5,0.75,0),(0,0.25,0.5)]\n",
    "    \n",
    "    colormap2 = [(0,0,0),'yellow',(0,0.5,0),(0.5,0.5,0),(0,0,0.5),(0.5,0,0.5),(0,0.5,0.5), \n",
    "                    (0.5,0.5,0.5),(0.25,0,0),(0.75,0,0),(0.25,0.5,0),(0.75,0.5,0),(0.25,0,0.5), \n",
    "                    (0.75,0,0.5),(0.25,0.5,0.5),(0.75,0.5,0.5),(0,0.25,0),(0.5,0.25,0),(0,0.75,0), \n",
    "                    (0.5,0.75,0),(0,0.25,0.5)]\n",
    "    \n",
    "    cmap = colors.ListedColormap(colormap)\n",
    "    cmap2 = colors.ListedColormap(colormap2)\n",
    "    bounds=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap2.N)\n",
    "   \n",
    "    \n",
    "    ax1.set_title('Groundtruth')\n",
    "    ax1.imshow(gt, cmap=cmap, norm=norm)\n",
    "\n",
    "    ax2.set_title('Output')\n",
    "    ax2.imshow(pred, cmap=cmap2, norm=norm)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 processd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m3kowal/anaconda3/lib/python3.7/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e5eee528aaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mget_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# -> VOC20000 mIOU = 0.736433 (0-padding)   ||    0.727015 (reflect padding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-e5eee528aaf3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mchannel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mint_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mint_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-bc1fa9e45f36>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# EVALUATION - student and supervisors\n",
    "def main():\n",
    "    \"\"\"Create the model and start the evaluation process.\"\"\"\n",
    "    args = get_arguments()\n",
    "\n",
    "    gpu0 = args.gpu\n",
    "\n",
    "    model = Res_Deeplab(num_classes=args.num_classes)\n",
    "    \n",
    "    saved_state_dict = torch.load(args.restore_from)\n",
    "    \n",
    "    #Load the trained supervisor parameters here:\n",
    "    int_saved_state_dict = torch.load('./Int_Snapshots/Binary_Error/REFLECT_PADDING/class_dependant/Lay100_BINARY_CLASS_DEPENDANT10000')\n",
    "    \n",
    "    '''#Loading and removing extra term infront of layer names if neccessary\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in saved_state_dict.items():\n",
    "        name = k[6:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    # load params\n",
    "    model.load_state_dict(new_state_dict)'''\n",
    "    \n",
    "    model.load_state_dict(saved_state_dict)\n",
    "    \n",
    "    model.eval()\n",
    "    model.cuda(gpu0)\n",
    "    layer = 99     #THIS DEFINES THE LAYER THAT THE SUPERVISOR GRABS ACTIVATIONS FROM\n",
    "    \n",
    "    \n",
    "    int_model = Decoder_Binary(input_size_list[layer])\n",
    "    #int_model = Decoder_Binary_weighting(input_size_list[layer], num_classes= NUM_CLASSES)\n",
    "    #int_model = Decoder_Multiclass_Weighting(input_size_list[layer], num_classes = NUM_CLASSES)\n",
    "    \n",
    "    \n",
    "    int_model.load_state_dict(int_saved_state_dict)\n",
    "    int_model.eval()\n",
    "    int_model.cuda(gpu0)\n",
    "    \n",
    "    VOCDataSet2 = VOCDataSet(args.data_dir,args.data_list, crop_size=(505, 505), mean=IMG_MEAN, scale=False, mirror=False)\n",
    "    \n",
    "    testloader = data.DataLoader(VOCDataSet2, batch_size=1, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    interp = nn.Upsample(size=(505, 505), mode='bilinear', align_corners=True)\n",
    "    \n",
    "    data_list = []\n",
    "    int_data_list = []\n",
    "    iou_list = []\n",
    "    confidence_list = []\n",
    "    DL_iou_list = []\n",
    "    \n",
    "    for index, batch in enumerate(testloader):\n",
    "        if index % 100 == 0:\n",
    "            print('%d processd'%(index))\n",
    "        image, label, size, name = batch \n",
    "        size = size[0].numpy()\n",
    "        \n",
    "        global activations\n",
    "        activations = []\n",
    "        \n",
    "        output = model(Variable(image).cuda(gpu0))\n",
    "        \n",
    "        image = Variable(image).cuda(gpu0)\n",
    "\n",
    "        output = interp(output).cpu().data[0].numpy()\n",
    " \n",
    "        \n",
    "        int_output_list = []\n",
    "        \n",
    "    \n",
    "        channel_size = activations[layer].size()[1]\n",
    "            \n",
    "        int_output = int_model(activations[layer])\n",
    "        \n",
    "        int_output = interp(int_output).cpu().data[0].numpy()\n",
    "\n",
    "        \n",
    "        int_output = int_output[:,:size[0],:size[1]]\n",
    "        int_output = int_output.transpose(1,2,0)\n",
    "        int_output = np.asarray(np.argmax(int_output, axis=2), dtype=np.int)\n",
    "                    \n",
    "        int_output_list.append(int_output)\n",
    "            \n",
    "        output = output[:,:size[0],:size[1]]\n",
    "        \n",
    "        gt = np.asarray(label[0].numpy()[:size[0],:size[1]], dtype=np.int)\n",
    "        \n",
    "        output = output.transpose(1,2,0)\n",
    "        output = np.asarray(np.argmax(output, axis=2), dtype=np.int)\n",
    "        \n",
    "        #int_gt = binary_gt_convert(output, gt)   #Class Independant\n",
    "        int_gt = class_gt_convert(output, gt)    #Class Dependant\n",
    "        #int_gt = class_out_gt_convert(output, gt)   #Multiclass\n",
    " \n",
    "        '''\n",
    "        if index < 50:\n",
    "            show_all(gt, output)\n",
    "            #show_all(int_gt, int_output)\n",
    "            show_all_binary(int_gt, int_output)        Uncomment to show the first 50 image outputs for both the student & supervisor\n",
    "            '''\n",
    "        \n",
    "        data_list.append([gt.flatten(), output.flatten()])\n",
    " \n",
    "        confidence_list.append(confidence_score(int_output_list[0], int_gt))\n",
    "        \n",
    "        #print(binary_IOU(int_output, int_gt))                  #Binary IOU\n",
    "        #iou_list.append(multiclass_IOU(int_output, int_gt))    #Multi-class IOU\n",
    "        \n",
    "        iou_list.append(binary_IOU(int_output, int_gt))\n",
    "        \n",
    "    print(\"meanIOU for intermediate network:\", sum(iou_list)/float(len(iou_list)))\n",
    "    get_iou(data_list, args.num_classes)\n",
    "\n",
    "main()\n",
    "\n",
    "# -> VOC20000 mIOU = 0.736433 (0-padding)   ||    0.727015 (reflect padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
